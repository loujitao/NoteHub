&emsp;<a href="#0">操作系统</a>  
&emsp;&emsp;<a href="#1">什么是操作系统</a>  
&emsp;&emsp;<a href="#2">什么是系统调用</a>  
&emsp;&emsp;<a href="#3">进程和线程（重）</a>  
&emsp;&emsp;&emsp;<a href="#4">进程和线程的区别</a>  
&emsp;&emsp;&emsp;<a href="#5">进程有几种状态</a>  
&emsp;&emsp;&emsp;<a href="#6">进程间的通信</a>  
&emsp;&emsp;&emsp;<a href="#7">线程间的同步</a>  
&emsp;&emsp;&emsp;<a href="#8">进程的调度算法</a>  
&emsp;&emsp;&emsp;<a href="#9">线程池</a>  
&emsp;&emsp;&emsp;<a href="#10">多线程</a>  
&emsp;&emsp;&emsp;<a href="#11">线程上下文切换</a>  
&emsp;&emsp;<a href="#12">死锁（重）</a>  
&emsp;&emsp;&emsp;<a href="#13">死锁产生的四个必要条件</a>  
&emsp;&emsp;&emsp;<a href="#14">解决死锁的方法</a>  
&emsp;&emsp;&emsp;&emsp;<a href="#15">死锁预防</a>  
&emsp;&emsp;&emsp;&emsp;<a href="#16">死锁避免</a>  
&emsp;&emsp;&emsp;&emsp;<a href="#17">死锁检测</a>  
&emsp;&emsp;&emsp;&emsp;<a href="#18">死锁解除</a>  
&emsp;&emsp;&emsp;<a href="#19">活锁</a>  
&emsp;&emsp;<a href="#20">操作系统内存管理</a>  
&emsp;&emsp;&emsp;<a href="#21">操作系统的内存管理</a>  
&emsp;&emsp;&emsp;<a href="#22">内存管理机制</a>  
&emsp;&emsp;&emsp;<a href="#23">快表和多级页表</a>  
&emsp;&emsp;&emsp;<a href="#24">逻辑地址和物理地址</a>  
&emsp;&emsp;&emsp;<a href="#25">CPU寻址和虚拟地址</a>  
&emsp;&emsp;<a href="#26">虚拟内存</a>  
&emsp;&emsp;&emsp;<a href="#27">什么是虚拟内存</a>  
&emsp;&emsp;&emsp;<a href="#28">局部性原理</a>  
&emsp;&emsp;&emsp;<a href="#29">虚拟内存的技术实现</a>  
&emsp;&emsp;&emsp;<a href="#30">页面置换算法</a>  
## <a name="0">操作系统


### <a name="1">什么是操作系统


```
- 运行在计算机上的软件程序，管理计算机硬件与软件资源的程序
- 屏蔽了硬件层的复杂性
- 操作系统的内核（Kernel）是操作系统的核心部分，它负责管理了
	- 内存管理
	- 文件系统管理
	- 硬件设备管理
	- 应用程序管理
```

### <a name="2">什么是系统调用


```
先了解下用户态和系统态：
	- 用户态：用户态运行的进程可直接读取用户程序的数据
	- 系统态：系统态运行的进程或程序可以访问计算机的任何资源
	
我们运行的程序基本都在用户态，当我们需要调用系统态基本的功能时，此时就需要系统调用，系统调用按功能可分：
	- 设备管理：设备的请求、释放、启动等
	- 文件管理：文件的读写、创建、删除等
	- 内存管理：进程的创建、撤销、阻塞、唤醒等
	- 进程控制：进程间的消息、信号传递
	- 进程通信：内存分配、回收以及获取作业占用内存大小及地址
```



### <a name="3">进程和线程（重）


<img src="https://yingziimage.oss-cn-beijing.aliyuncs.com/img/202302071655776.png" style="zoom:50%;" />

#### <a name="4">进程和线程的区别


```
从JVM角度讨论两者的关系：
	一个进程中可以有多个线程，多个线程共享进程的堆、方法区资源
	每个线程有自己独立的程序计数器、虚拟机栈、本地方法栈
	
进程：操作系统资源分配的基本单位；进程间切换有较大开销
线程：处理器任务调度、执行的基本单位；线程间切换有较小开销
```



#### <a name="5">进程有几种状态


```
大致分为5种状态：
	创建状态(new)、就绪状态(ready)、运行状态(running)、阻塞状态(waiting)、结束状态(terminated)
```

#### <a name="6">进程间的通信


```
大概有7种常见的进程间的通信方式：
	匿名管道：具有亲缘关系的父子、兄弟进程间的通信
	有名管道：遵循先进先出，以磁盘文件的方式存在，可以实现本机任意两个进程通信
	信号：通知接收的进程某个事件已经发生
	消息队列：遵循先进先出，存放在内核中，只有内核重启或显式删除一个消息队列时该消息队列才会被真正删除，可实现消息的随机查询。克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点
	信号量：一个计数器，用于多进程堆共享数据的访问，解决了同步相关的问题并避免竞争条件。
	共享内存：多个进程可访问同一块内存空间，不同进程可看到相互间对共享内存中的数据更新，实现依赖于同步操作，如互斥锁、信号量等
	套接字：用于在客户端和服务端之间通过网络通信，是支持TCP/IP的网络通信的基本操作单元
```

#### <a name="7">线程间的同步


```
两个或多个共享关键资源的线程并发执行，一般是下面三种线程同步方式：
	互斥量(Mutex)：互斥对象机制，只有拥有互斥对象的线程才由访问公共资源的权限。如java中的synchronized、Lock都是这种机制
	信号量(Semaphore)：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问次资源的最大线程数量
	事件(Event)：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作
```



#### <a name="8">进程的调度算法


```
先到先服务：从就绪队列中选择一个最先进入该队列的进程为之分配资源
短作业优先：从就绪队列中选择一个运行时间最短的进程为之分配资源
时间片轮转：Round robin，最古老、最简单、最公平且使用最广的算法，为每个进程分配一个时间段，即该进程允许运行的时间
优先级：为每个流程分配优先级，首先执行具有最高优先级的进程。若优先级相同则以先到先服务方式执行。
多级反馈队列：既能使高优先级的作业得到响应又能短作业（进程）迅速完成
```

#### <a name="9">线程池


```
池化技术在开发中比较常见，如线程池、数据库连接池、Http连接池等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。

线程池的利：
	1.减低资源消耗。通过重复利用已创建的线程降低线程动态创建和销毁造成的消耗
	2.提高响应速度。当任务到达时，任务可不需要等到线程创建就能立即执行，减少了创建线程这段时间的开销
	3.提高线程的可管理性。线程是稀缺资源，若无限制创建，不仅会消耗系统资源，还会降低系统稳定性。使用线程池可进行统一分配、调优、监控
```

#### <a name="10">多线程


```
花销小，切换快
	- 在Linux系统下,启动一个新的进程必须分配给它独立的地址空间,建立众多的数据表(即PCB中的资源分配清单)来维护它的代码段、数据段、堆栈段,这是一种"昂贵"的多任务工作方式。而运行于一个进程中的多个线程,它们彼此之间使用相同的地址空间,共享大部分数据,启动一个线程所花费的空间远远小于启动一个进程所花费的空间,而且,线程间彼此切换所需的时间也远远小于进程间切换所需要的时间
方便的通信机制
	- 对不同进程来说，它们具有独立的数据空间,要进行数据的传递只能通过通信的方式进行,这种方式不仅费时,而且很不方便。线程则不然,由于同一进程下的线程之间共享数据空间,所以一个线程的数据可以直接为其它线程所用,这不仅快捷,而且方便
```

#### <a name="11">线程上下文切换


![](https://yingziimage.oss-cn-beijing.aliyuncs.com/img/202302101643395.png)

```
任务状态的保存再加载的过程
	- 巧妙地利用时间片轮转的方式，CPU给每个任务都服务一定的时间，然后把当前任务的状态保存下来，在加载下一任务的状态后继续服务下一任务

上下文切换活动
	- 挂起一个进程，将这个进程在CPU中的状态存储于内存中的某处
	- 在内存中检索下一个进程的上下文，并将其在CPU寄存器中恢复
	- 跳转到程序计数器所指的位置（即跳转到进程被中断时的代码行），以恢复该进程在程序中

引起线程上下文切换的原因
	- 当前执行任务的时间片用完之后，系统CPU正常调度下一个任务
	- 当前执行任务碰到IO阻塞，调度器将此任务挂起，继续下一任务
	- 多任务抢占锁资源，当前任务没强盗锁资源，被调度器挂起，继续下一任务
	- 用户代码挂起当前任务，让出CPU时间
	- 硬件中断
```



### <a name="12">死锁（重）


#### <a name="13">死锁产生的四个必要条件


```
死锁：两个或两个以上的进程（线程）在执行过程中，因争夺资源而造成的一种互相等待现象，若无外力作用，它们都将无法推进下去。此时称		 系统处于死锁状态

互斥：多个线程不能使用同一个资源
持有等待：在申请新资源的同时，保持对原资源的占用
不可剥夺：资源申请者不能强行从资源占用者夺取资源，资源只能由占有着资源释放
环路等待：死锁发生时，一组进程在获取资源时形成了环形链
```

#### <a name="14">解决死锁的方法


```
解决死锁的方法一般情况下有预防、避免、检测、解除：
	预防：采用某种策略，限制并发进程对资源的请求，从而使得死锁的必要条件在系统执行的任何时间上都不满足
	避免：在系统分配资源时，根据资源使用情况提前做出预测，从而避免死锁的发生
	检测：系统设有专门的机构，当死锁发生时，该机构能检测死锁发生并精确确定与死锁有关的进程和资源
	解除：将进程从死锁状态下解脱出来
```

##### <a name="15">死锁预防


```
对于死锁产生的四个必要条件，只要破坏其中一个条件，就可以预防死锁的发生：
	破环互斥：资源可同时访问（例如磁盘）。但很多资源往往不能同时访问，该方法在很多场合不适用
	破坏持有等待：一次性申请所有资源
	破坏不可剥夺：占用部分资源的线程申请其他资源时，若申请不到，主动释放它占用的资源
	破坏环路等待：层次分配，所有资源被分成多个层次。一个进程得到某资源后只能申请较高一层的资源；一个资源释放资源只能先释放较高层的资源
```

##### <a name="16">死锁避免


```
破坏死锁产生的四个必要条件之一就可以<预防>系统发生死锁，但会导致低效的进程运行、资源使用率

死锁避免允许系统中同时存在四个必要条件。系统分为安全、不安全状态，保持系统处于安全状态从而避免死锁的典型算法是银行家算法
	- 银行家算法：当一个进程申请使用资源时，先试探分配给该进程资源后，由安全性算法判断分配后系统是否处于安全状态，若不安全则试探分配作废，该进程继续等待，若安全就分配
```

##### <a name="17">死锁检测


```
检测系统是否产生死锁：
	1.若进程-资源分配图中无环路，则此时系统没有发生死锁
	2.若进程-资源分配图中有环路，且每个资源类仅有一个资源，则系统发生了死锁
	3.若进程-资源分配图中有换图，且资源类有多个资源。若进程-资源分配图中能找出一个既不阻塞又非独立的进程，该进程在有限时间内归还占用的资源，也就是把边消除了，重复此过程，直至在有限时间内消除所有边，则不会发生死锁。
```

##### <a name="18">死锁解除


```
常用解除死锁的方法有以下四种：
	- 立即结束所有进程的执行，重新启动操作系统：方法简单，但以前所有工作全部作废，损失很大
	- 撤销涉及死锁的所有进程，解除死锁后继续运行：打破了死锁的循环等待条件
	- 逐个撤销涉及死锁的进程，回收资源直至死锁解除
	- 抢占资源：从涉及死锁的一个或机构进程中抢占资源，把夺得的资源再分配给涉及死锁的进程直至死锁解除
```

#### <a name="19">活锁


```
多线程中出现了相互谦让，都主动将资源释放给其他线程使用，资源在多个线程间转让而得不到执行，形成活锁

解决活锁的办法：线程在获取资源之前，随机休眠一段时间
```



### <a name="20">操作系统内存管理




#### <a name="21">操作系统的内存管理


```
主要负责内存的分配与回收：
	- malloc函数；申请内存
	- free函数：释放内存
	
将逻辑（虚拟）地址转换成相应的物理地址
```

#### <a name="22">内存管理机制


```
简单分为连续分配、非连续分配两种。
	- 连续分配：为一个用户程序分配一个连续的内存空间，常见的如 块式管理
	- 非连续分配：允许一个用户程序使用的内存分布在离散（不相邻）的内存中，常见的如 页式管理、段式管理
	
块式管理：远古时代的计算机操作系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程，若程序运行需要内存，操作			系统就分配给它一块，若程序运行只需要很小的空间，则分配的块中大量内存被浪费，这些块中未被利用的空间被称为碎片
页式管理：把主存分为大小相等且固定的一页一页的形式，相比于块式管理的划分粒度更小，提高内存利用率，减少了碎片。可通过页表对应逻			辑地址和物理地址
段式管理：页式管理其中的页并无任何实际意义。段式管理把主存分为一段段的，段具有实际意义，每个段定义了一组逻辑信息。例如，有主程			 序段MAIN、子程序段X、数据段D及栈段S等。可通过段表对应逻辑地址和物理地址
段页式：结合了页式、段式的优点。把主存先分成若干段，每个段又分为若干页

分段和分页：
    共同点：
        - 提高内存利用率，减少内存碎片
        - 页和段都是离散的，两者都是离散分配内存的方式。但每个页和段中的内存是连续的
    区别：
        - 页大小固定，由操作系统决定；段大小不固定，取决于当前的运行程序
        - 页是物理单位，分页仅仅是为了满足操作系统内存管理的需求；段是逻辑单位（在程序中可体现为代码段、数据段），分段可更好满足用户需求
```

#### <a name="23">快表和多级页表


```
在页式内存管理中，很重要的两点：
	- 快表：解决虚拟地址到物理地址的转换要快
	- 多级页表：解决虚拟地址空间大，页表页很大的问题

快表：快表可理解位一种特殊的高速缓冲存储器（Cache），使用快表后的地址转换流程（类似Redis）：
		1.根据虚拟地址的页号查快表
		2.若该页在快表中，则直接从快表中读取相应的物理地址
     	 3.若该页不在快表中，就访问内存中的页表，从页表中获取物理地址，同时将该页表的映射表添加到快表中
     	 4. 当快表填满后又需登记新页表时，按照一定的淘汰策略淘汰掉快表中的一个页
     	 
多级页表：避免把全部页表一直存放在内存中占用过多空间，特别是哪些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景。
```

#### <a name="24">逻辑地址和物理地址


```
逻辑地址：操作系统决定，编程一般只和逻辑地址打交道
物理地址：真实物理内存中的地址，更具体来说是内存地址寄存器中的地址，物理地址是内存单元真正的地址
```



#### <a name="25">CPU寻址和虚拟地址


```
虚拟寻址（Virtual Addressing）：现代处理器使用一种寻址方式，CPU中含有一个内存管理单元（Memory Management Unit,MMU）,负责将虚拟地址翻译成物理地址

程序直接访问和操作都是物理内存，会出现什么问题？
	1. 用户程序可以访问任意内存，寻找内存的每个字节，这样很容易破坏操作系统
	2. 同时运行多个程序特别困难，若想同时运行一个微信和QQ。微信在运行的时候给内存地址1xxx赋值后，QQ也同样给内存地址1xxx赋值，覆盖了微信所赋值，导致微信这个程序崩溃。
	
虚拟地址访问的优势如下：
	- 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存
	- 程序可使用一系列的虚拟地址来访问物理内存中不相邻的内存缓冲区
	- 程序可使用一系列的虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小，内存管理器会将物理内存页（通常大小为4KB）保存到磁盘文件中，数据或代码页会根据需要在物理内存与磁盘之间移动
```



### <a name="26">虚拟内存


#### <a name="27">什么是虚拟内存


```
虚拟内存是计算机系统内存管理的一种技术，我们可以手动设置自己电脑的虚拟内存。
	- 虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）
	- 把内存扩展到硬盘空间
```

#### <a name="28">局部性原理


```
局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就可开始运行

局部性原理表现在以下两方面：
	- 时间局部性：若程序中的某条指令一旦执行，不久后该指令可再次被执行；若某数据被访问过，不久后该数据可再次被访问。产生时间局部性的典型原因是，程序中存在大量的循环操作。
	- 空间局部性：若程序访问了某个存储单元，不久后附近的存储单元也将被访问，即程序在一段时间内所访问的地址可能集中在一定范围内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储

补充：
	- 时间局部性是通过将近来使用的指令、数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现
	- 空间局部性是通过较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。
	
虚拟内存技术实际上就是建立了“内存-外存”的两级存储器结构，利用局部性原理实现高速缓存
```



#### <a name="29">虚拟内存的技术实现


```
虚拟内存的实现建立在离散分配的内存管理方式的基础上，有以下三种方式：
	- 请求分页存储管理：建立在分页管理上，增加了请求调页、页面置换功能
		- 请求分页是目前最常用的一种实现虚拟存储器的方法
		- 请求分页存储管理系统中，在作业开始运行前，仅装入当前要执行的部分段即可运行
		- 若作业在运行过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的 页面置换算法 将相应的页面调入到主存，同时操作系统也可将暂时用不到的页面置换到外存中
	- 请求分段存储管理：建立在分段管理上，增加了调段、分段置换功能
		- 在作业开始运行前，仅装入当前要执行的部分段即可执行
		- 作业在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段
		- 内存已满却又需要装入新段，可根据 置换功能适当调出某个段，以便腾出空间而装入新段

请求分页、分页存储管理的根本区别
	- 它们是否将一作业的全部地址空间同时装入主存。请求分页存储管理不要求将作业全部地址空间同时装入主存，基于这一点，请求分页可提供虚拟内存，分页存储管理却不提供虚拟内存

总结：
	1. 一定容量的内存和外存：在载入程序时，只需将程序一部分装入内存，而将其他部分留在外存，然后程序可执行
	2. 缺页中断：若需执行的指令或访问数据尚未在内存（缺页或缺段），则由处理器通知操作系统将相应的页面(段)调入到内存，然后继续执行程序
	3. 虚拟地址空间；逻辑地址到物理地址的变换
```

#### <a name="30">页面置换算法


```
缺页中断：若要访问的页不在主存，就需要操作系统将其调入主存后再进行访问，这个时候被内存映射的文件实际上成了一个分页交换文件

页面置换算法：
	- OPT（最佳）：所选择的淘汰页面将是以后永不使用（或再最长时间内不被访问的页面），这样可保证最低的缺页率。但由于人们目前无法预知进程在内存在的若干页面中哪个时未来最长时间内不再被访问，故而该算法无法被实现，一般作为衡量其他置换算法的方法
	- FIFO（First In First Out,先进先出）：总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰
	- LRU（Least Recently Used,最近最久未使用）：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间T，当需要淘汰时，选择现有页面T值最大（即最近最久未使用）的淘汰
	- LFU（Least Frequently Used,最少使用）：选择在之前使其使用最少的页面作为淘汰页
```



